{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Duplicate Questions classification\n",
    "###  Kaggle competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration & Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import string\n",
    "import nltk\n",
    "from nltk.metrics import *\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_base = pd.read_csv('data/train.csv')\n",
    "df_train_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adarsh/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 976 ms, total: 1min 20s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#punctable =str.maketrans({key: \"\" for key in string.punctuation})\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "for qcol in ['question1','question2']:\n",
    "    df_train_base['act_len_' + qcol ] = df_train_base[qcol].apply(lambda x: len(str(x).split()))\n",
    "    #df_train_base[qcol] = df_train_base[qcol].apply(lambda x: str(x).lower().translate(punctable))\n",
    "    df_train_base[qcol] = df_train_base[qcol].apply(lambda x: str(x).lower().translate(None, string.punctuation))\n",
    "    df_train_base[qcol] = df_train_base[qcol].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))\n",
    "    df_train_base['imp_len_' + qcol ] = df_train_base[qcol].apply(lambda x: len(str(x).split()))\n",
    "    #Binary encoding for the type of question - {'what','how','why','where','which'}\n",
    "    for qtype in ['what','why','where','how','which']:\n",
    "        df_train_base[qtype+'_'+qcol] = df_train_base[qcol].apply(lambda x: (qtype in str(x).lower())*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590018, 3)\n",
      "   qid                                           question  type\n",
      "0    1          step step guide invest share market india     1\n",
      "1    3                    story kohinoor kohinoor diamond     1\n",
      "2    5       increase speed internet connection using vpn     1\n",
      "3    7                              mentally lonely solve     1\n",
      "4    9  one dissolve water quikly sugar salt methane c...     1\n",
      "CPU times: user 442 ms, sys: 115 ms, total: 558 ms\n",
      "Wall time: 571 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question1 = df_train_base[['qid1','question1']].drop_duplicates().rename(columns={'qid1':'qid','question1':'question'})\n",
    "question1['type'] = 1\n",
    "question2 = df_train_base[['qid2','question2']].drop_duplicates().rename(columns={'qid2':'qid','question2':'question'})\n",
    "question2['type'] = 2\n",
    "allquestions = pd.concat([question1,question2])\n",
    "print (allquestions.shape)\n",
    "print (allquestions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 307 ms, total: 10.6 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.9,max_features=2000,\n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(allquestions.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparse_max_row(csr_mat):\n",
    "    ret = np.maximum.reduceat(csr_mat.data, csr_mat.indptr[:-1])\n",
    "    ret[np.diff(csr_mat.indptr) == 0] = 0\n",
    "    return ret\n",
    "\n",
    "def min_sparse(X):\n",
    "    if len(X.data) == 0:\n",
    "        return 0\n",
    "    m = X.data.min()\n",
    "    return m if X.getnnz() == X.size else min(m, 0)\n",
    "\n",
    "allquestions['tfidf_score'] = tfidf.sum(axis=1)\n",
    "allquestions['tfidf_max'] =sparse_max_row(tfidf)\n",
    "allquestions['tfidf_min'] =[min_sparse(tfidf.getrow(i)) for i in range(tfidf.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>type</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>tfidf_max</th>\n",
       "      <th>tfidf_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>1</td>\n",
       "      <td>1.998898</td>\n",
       "      <td>0.788155</td>\n",
       "      <td>0.208347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>increase speed internet connection using vpn</td>\n",
       "      <td>1</td>\n",
       "      <td>2.220270</td>\n",
       "      <td>0.537069</td>\n",
       "      <td>0.372623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.985718</td>\n",
       "      <td>0.540787</td>\n",
       "      <td>0.393676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                           question  type  tfidf_score  \\\n",
       "0    1          step step guide invest share market india     1     1.998898   \n",
       "1    3                    story kohinoor kohinoor diamond     1     1.000000   \n",
       "2    5       increase speed internet connection using vpn     1     2.220270   \n",
       "3    7                              mentally lonely solve     1     1.000000   \n",
       "4    9  one dissolve water quikly sugar salt methane c...     1     1.985718   \n",
       "\n",
       "   tfidf_max  tfidf_min  \n",
       "0   0.788155   0.208347  \n",
       "1   1.000000   1.000000  \n",
       "2   0.537069   0.372623  \n",
       "3   1.000000   1.000000  \n",
       "4   0.540787   0.393676  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allquestions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_dist(sent1, sent2, func):\n",
    "    # to take care of division by zero errors\n",
    "    #print(sent1)\n",
    "    try:\n",
    "        res = func(set(sent1.split()), set(sent2.split()))\n",
    "    except:\n",
    "        res=0\n",
    "    return res\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def get_word_match_share(sent1, sent2, get_stems = True):\n",
    "    res = 0\n",
    "    words1 = sent1.split()\n",
    "    words2 = sent2.split()\n",
    "    if (len(words1) + len(words2)) >0:\n",
    "        res = 2*len(set(words1).intersection(set(words2)))/(len(words1) + len(words2))\n",
    "    if get_stems:\n",
    "        try:\n",
    "            words1 = stem_tokens(words1, stemmer)\n",
    "            words2 = stem_tokens(words2, stemmer)    \n",
    "            if (len(words1) + len(words2)) >0:\n",
    "                res = 2*len(set(words1).intersection(set(words2)))/(len(words1) + len(words2))\n",
    "        except:\n",
    "            pass\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act_len_diff', 'imp_len_diff', 'tfidf_score_diff', 'word_match_share', 'jaccard_dist', 'masi_dist', 'what_diff', 'why_diff', 'where_diff', 'how_diff', 'which_diff', 'tfidf_score_question1', 'tfidf_score_question2', 'tfidf_max_question1', 'tfidf_max_question2', 'tfidf_min_question1', 'tfidf_min_question2', 'what_question1', 'what_question2', 'why_question1', 'why_question2', 'where_question1', 'where_question2', 'how_question1', 'how_question2', 'which_question1', 'which_question2']\n"
     ]
    }
   ],
   "source": [
    "features = ['act_len_diff','imp_len_diff','tfidf_score_diff','word_match_share'\n",
    "            ,'jaccard_dist','masi_dist'\n",
    "            ,'what_diff','why_diff','where_diff','how_diff','which_diff']\n",
    "\n",
    "questions = ['question1','question2']\n",
    "fields = ['tfidf_score','tfidf_max','tfidf_min','what','why','where','how','which']\n",
    "features = features + [field + '_' + question for field in fields for question in questions]\n",
    "y_col = 'is_duplicate'\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   act_len_diff  imp_len_diff  tfidf_score_diff  word_match_share  \\\n",
      "0             2             1          0.168171          0.769231   \n",
      "1            -5            -5         -0.727128          0.307692   \n",
      "2             1             1          0.000000          0.285714   \n",
      "3             0             0         -0.413921          0.500000   \n",
      "4             2            -1         -0.387095          0.222222   \n",
      "\n",
      "   jaccard_dist  masi_dist  what_diff  why_diff  where_diff  how_diff  \\\n",
      "0      0.166667   0.441667          0         0           0         0   \n",
      "1      0.777778   0.926667          0         0           0         0   \n",
      "2      1.000000   1.000000          0         0           0         0   \n",
      "3      0.600000   0.868000          0         0           0         0   \n",
      "4      0.857143   0.952857          0         0           0         0   \n",
      "\n",
      "       ...       what_question2  why_question1  why_question2  \\\n",
      "0      ...                    0              0              0   \n",
      "1      ...                    0              0              0   \n",
      "2      ...                    0              0              0   \n",
      "3      ...                    0              0              0   \n",
      "4      ...                    0              0              0   \n",
      "\n",
      "   where_question1  where_question2  how_question1  how_question2  \\\n",
      "0                0                0              0              0   \n",
      "1                0                0              0              0   \n",
      "2                0                0              0              0   \n",
      "3                0                0              0              0   \n",
      "4                0                0              0              0   \n",
      "\n",
      "   which_question1  which_question2  is_duplicate  \n",
      "0                0                0             0  \n",
      "1                0                0             0  \n",
      "2                0                0             0  \n",
      "3                0                0             0  \n",
      "4                0                0             0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.merge(df_train_base, allquestions[allquestions.type==1], left_on='qid1',right_on='qid')\n",
    "df_train = pd.merge(df_train, allquestions[allquestions.type==2], left_on='qid2',right_on='qid', suffixes=('_question1','_question2'))\n",
    "df_train['jaccard_dist'] = df_train.apply(lambda row: get_dist(row['question_question1'], \n",
    "                                                        row['question_question2'], jaccard_distance)\n",
    "                                                         , axis=1)\n",
    "df_train['masi_dist'] = df_train.apply(lambda row: get_dist(row['question_question1'], \n",
    "                                                        row['question_question2'], masi_distance)\n",
    "                                                         , axis=1)\n",
    "df_train['word_match_share'] = df_train.apply(lambda row: get_word_match_share(row['question_question1'], row['question_question2']), axis=1)\n",
    "\n",
    "for col in ['act_len','imp_len','tfidf_score']:\n",
    "    df_train[col+'_diff'] = df_train[col+'_question1'] - df_train[col+'_question2']\n",
    "for qtype in ['what','why','where','how','which']:\n",
    "     df_train[qtype + '_'  + 'diff'] = (df_train[qtype+'_question1'] != df_train[qtype + '_question2']).astype(int)\n",
    "print (df_train[features + [y_col]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - test dataset split\n",
    "70:30 split for train and test. Test set will only be used for validation. Train set may be further split for further cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "seed= 32\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_train[features], df_train[y_col], test_size=0.3,random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a test classifier to establish baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 1.57 s, total: 1min 38s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.74513\n",
      "ROC AUC = 0.72612\n",
      "Log Loss = 0.50675\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "pred_proba = clf.predict_proba(X_test)\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "print('Accuracy = %1.5f' % accuracy_score(Y_test, preds))\n",
    "print('ROC AUC = %1.5f' % roc_auc_score(Y_test, preds))\n",
    "print('Log Loss = %1.5f' % log_loss(Y_test, pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.12446123074336882, 'jaccard_dist'),\n",
       " (0.10845770101023272, 'masi_dist'),\n",
       " (0.093708665726030885, 'word_match_share'),\n",
       " (0.083858870213419257, 'tfidf_score_diff'),\n",
       " (0.081898587281253779, 'tfidf_min_question1'),\n",
       " (0.081159800417174133, 'tfidf_max_question1'),\n",
       " (0.080938690931960072, 'tfidf_min_question2'),\n",
       " (0.08093734183512559, 'tfidf_score_question1'),\n",
       " (0.080915737851055769, 'tfidf_score_question2'),\n",
       " (0.080483083124224641, 'tfidf_max_question2')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(clf.feature_importances_, features), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training data into a pickle for next stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.to_pickle('data/X_train.pkl')\n",
    "Y_train.to_pickle('data/Y_train.pkl')\n",
    "X_test.to_pickle('data/X_test.pkl')\n",
    "Y_test.to_pickle('data/Y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train[features + [y_col]].to_pickle('data/df_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the validation set with the same transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_base = pd.read_csv('data/test.csv')\n",
    "df_test_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adarsh/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 2s, sys: 4.92 s, total: 6min 7s\n",
      "Wall time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#punctable =str.maketrans({key: \"\" for key in string.punctuation})\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "for qcol in ['question1','question2']:\n",
    "    df_test_base['act_len_' + qcol ] = df_test_base[qcol].apply(lambda x: len(str(x).split()))\n",
    "    #df_test_base[qcol] = df_test_base[qcol].apply(lambda x: str(x).lower().translate(punctable))\n",
    "    df_test_base[qcol] = df_test_base[qcol].apply(lambda x: str(x).lower().translate(None, string.punctuation))\n",
    "    df_test_base[qcol] = df_test_base[qcol].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))\n",
    "    df_test_base['imp_len_' + qcol ] = df_test_base[qcol].apply(lambda x: len(str(x).split()))\n",
    "    for qtype in ['what','why','where','how','which']:\n",
    "        df_test_base[qtype+'_'+qcol] = df_test_base[qcol].apply(lambda x: (qtype in str(x).lower())*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4691592, 3)\n",
      "   qid                                question  type\n",
      "0    0          surface pro 4 compare ipad pro     1\n",
      "1    1  hair transplant age 24 much would cost     1\n",
      "2    2            best way send money china us     1\n",
      "3    3                        food emulsifiers     1\n",
      "4    4               aberystwyth start reading     1\n",
      "CPU times: user 3.32 s, sys: 664 ms, total: 3.98 s\n",
      "Wall time: 3.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question1 = df_test_base[['test_id','question1']].drop_duplicates().rename(columns={'test_id':'qid','question1':'question'})\n",
    "question1['type'] = 1\n",
    "question2 = df_test_base[['test_id','question2']].drop_duplicates().rename(columns={'test_id':'qid','question2':'question'})\n",
    "question2['type'] = 2\n",
    "allquestions_test = pd.concat([question1,question2])\n",
    "print (allquestions_test.shape)\n",
    "print (allquestions_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = tfidf_vectorizer.transform(allquestions_test.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allquestions_test['tfidf_score'] = tfidf.sum(axis=1)\n",
    "allquestions_test['tfidf_max'] = sparse_max_row(tfidf)\n",
    "allquestions_test['tfidf_min'] = [min_sparse(tfidf.getrow(i)) for i in range(tfidf.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>type</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>tfidf_max</th>\n",
       "      <th>tfidf_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>1</td>\n",
       "      <td>1.998898</td>\n",
       "      <td>0.788155</td>\n",
       "      <td>0.208347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>increase speed internet connection using vpn</td>\n",
       "      <td>1</td>\n",
       "      <td>2.220270</td>\n",
       "      <td>0.537069</td>\n",
       "      <td>0.372623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.985718</td>\n",
       "      <td>0.540787</td>\n",
       "      <td>0.393676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                           question  type  tfidf_score  \\\n",
       "0    1          step step guide invest share market india     1     1.998898   \n",
       "1    3                    story kohinoor kohinoor diamond     1     1.000000   \n",
       "2    5       increase speed internet connection using vpn     1     2.220270   \n",
       "3    7                              mentally lonely solve     1     1.000000   \n",
       "4    9  one dissolve water quikly sugar salt methane c...     1     1.985718   \n",
       "\n",
       "   tfidf_max  tfidf_min  \n",
       "0   0.788155   0.208347  \n",
       "1   1.000000   1.000000  \n",
       "2   0.537069   0.372623  \n",
       "3   1.000000   1.000000  \n",
       "4   0.540787   0.393676  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allquestions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 40s, sys: 18.1 s, total: 12min 58s\n",
      "Wall time: 12min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test = pd.merge(df_test_base, allquestions_test[allquestions_test.type==1], left_on='test_id',right_on='qid', how='left')\n",
    "df_test = pd.merge(df_test, allquestions_test[allquestions_test.type==2], left_on='test_id',right_on='qid', suffixes=('_question1','_question2'), how='left')\n",
    "df_test['jaccard_dist'] = df_test.apply(lambda row: get_dist(row['question_question1'], \n",
    "                                                        row['question_question2'], jaccard_distance)\n",
    "                                                         , axis=1)\n",
    "df_test['masi_dist'] = df_test.apply(lambda row: get_dist(row['question_question1'], \n",
    "                                                        row['question_question2'], masi_distance)\n",
    "                                                         , axis=1)\n",
    "df_test['word_match_share'] = df_test.apply(lambda row: get_word_match_share(row['question_question1'], row['question_question2']), axis=1)\n",
    "\n",
    "for col in ['act_len','imp_len','tfidf_score']:\n",
    "    df_test[col+'_diff'] = df_test[col+'_question1'] - df_test[col+'_question2']\n",
    "for qtype in ['what','why','where','how','which']:\n",
    "     df_test[qtype + '_'  + 'diff'] = (df_test[qtype+'_question1'] != df_test[qtype + '_question2']).astype(int)\n",
    "\n",
    "df_test[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[features].to_pickle('data/df_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
